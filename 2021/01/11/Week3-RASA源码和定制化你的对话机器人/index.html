<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"marchboy.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="一、Setting up RASA Source Code1234567891011121314151617181920212223242526272829303132### Step-1、Python Environment SetupPython环境配置、创建新的虚拟环境以及pip的安装方法，详见Week2笔记### Step-2、Building from Source### 这里介绍源码的">
<meta property="og:type" content="article">
<meta property="og:title" content="week3-RASA源码和定制化你的对话机器人">
<meta property="og:url" content="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/index.html">
<meta property="og:site_name" content="ComputerScience">
<meta property="og:description" content="一、Setting up RASA Source Code1234567891011121314151617181920212223242526272829303132### Step-1、Python Environment SetupPython环境配置、创建新的虚拟环境以及pip的安装方法，详见Week2笔记### Step-2、Building from Source### 这里介绍源码的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/component-lifecycle-img.png">
<meta property="og:image" content="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/NLUModule.png">
<meta property="og:image" content="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/extractors.png">
<meta property="og:image" content="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/NLUCOMPONENT.png">
<meta property="article:published_time" content="2021-01-10T16:00:00.000Z">
<meta property="article:modified_time" content="2021-04-17T17:48:46.788Z">
<meta property="article:author" content="进军要努力呀">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="任务型对话">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/component-lifecycle-img.png">

<link rel="canonical" href="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>week3-RASA源码和定制化你的对话机器人 | ComputerScience</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-74793810-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-74793810-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a5f7448ac0b523badc121b2d870f1b0c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ComputerScience</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">温故而知新</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="进军要努力呀">
      <meta itemprop="description" content="可怕的是自己内心的堕落">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ComputerScience">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          week3-RASA源码和定制化你的对话机器人
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-01-11 00:00:00" itemprop="dateCreated datePublished" datetime="2021-01-11T00:00:00+08:00">2021-01-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-04-18 01:48:46" itemprop="dateModified" datetime="2021-04-18T01:48:46+08:00">2021-04-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D/" itemprop="url" rel="index"><span itemprop="name">任务型对话</span></a>
                </span>
            </span>

          
            <span id="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/" class="post-meta-item leancloud_visitors" data-flag-title="week3-RASA源码和定制化你的对话机器人" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>26k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="一、Setting-up-RASA-Source-Code"><a href="#一、Setting-up-RASA-Source-Code" class="headerlink" title="一、Setting up RASA Source Code"></a>一、Setting up RASA Source Code</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Step-1、Python Environment Setup</span></span></span><br><span class="line">Python环境配置、创建新的虚拟环境以及pip的安装方法，详见Week2笔记</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Step-2、Building from Source</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 这里介绍源码的安装方法</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Step-3、安装poetry</span></span></span><br><span class="line">curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关于poetry，截至目前pypi并未托管potery的whl文件，如果上述指令执行缓慢，或者由于网络原因不能下载；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可下载poetry.py和poetry源码，执行以下命令行安装；</span></span><br><span class="line">python get-poetry.py --file poetry-1.1.4-win32.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Step-4、下载rasa源码</span></span></span><br><span class="line">git clone https://github.com/RasaHQ/rasa.git</span><br><span class="line">cd rasa</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Step-5、安装</span></span></span><br><span class="line">poetry install</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 总结下安装过程：</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## poetry install对网络的要求很高，如果中途网络断开，再次执行poetry install会直接报错，这里尚不清楚为何重复执行后不会像pip那样重新请求网络资源安装，而是会直接出错。迫不得已，手动pip安装了poetry.lock文件要求的包版本，再执行poetry install至成功安装，非常耗时，前前后后折腾约2小时。</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## STEP-6:特别地，若有需要安装RASA的附加依赖，如：</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Dependencies <span class="keyword">for</span> spaCy</span></span><br><span class="line">pip3 install rasa[spacy]</span><br><span class="line">python3 -m spacy download en_core_web_md</span><br><span class="line">python3 -m spacy link en_core_web_md en</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Dependencies <span class="keyword">for</span> MITIE</span></span><br><span class="line">pip3 install git+https://github.com/mit-nlp/MITIE.git</span><br><span class="line">pip3 install rasa[mitie]    # pip list可以查看到已安装好了mitie包</span><br></pre></td></tr></table></figure>


<h3 id="二、Optimize-NLU"><a href="#二、Optimize-NLU" class="headerlink" title="二、Optimize NLU"></a>二、Optimize NLU</h3><h4 id="2-0-如何增强RASA-NLU-Lifestyle"><a href="#2-0-如何增强RASA-NLU-Lifestyle" class="headerlink" title="2.0 如何增强RASA NLU - Lifestyle"></a>2.0 如何增强RASA NLU - Lifestyle</h4><p><img src="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/component-lifecycle-img.png"></p>
<p>Create: 在训练之前初始化Component</p>
<p>Train：当前Component使用上下文和先前Component的输出进行训练</p>
<p>Persist：持久化，将训练好的component保存在磁盘</p>
<h4 id="2-1、Improve-NLU"><a href="#2-1、Improve-NLU" class="headerlink" title="2.1、Improve NLU"></a>2.1、Improve NLU</h4><h5 id="2-1-0、RASA-NLU-模块的作用"><a href="#2-1-0、RASA-NLU-模块的作用" class="headerlink" title="2.1.0、RASA NLU 模块的作用"></a>2.1.0、RASA NLU 模块的作用</h5><p>分词、训练词向量、提取特征、命名体识别、意图识别等，这些功能都是通过不同的components实现的，然后通过pipeline将这些components组装在一起，得到NLU过程输出的结果：用户的intent和entity。</p>
<h5 id="2-1-1、Components组件"><a href="#2-1-1、Components组件" class="headerlink" title="2.1.1、Components组件"></a>2.1.1、Components组件</h5><p>关于Component：</p>
<p>在RASA源码NLU模块中（./rasa-master/rasa/nlu），其代码结构：</p>
<p><img src="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/NLUModule.png"></p>
<p>其中，在components.py文件中定义了component类，每一个component都是pipeline中处理数据的一个单元，按照在pipeline中的顺序执行。在上图中包含classifiers\emulators\ extractors\featurizers\ selectors\tokenizers文件，每一个文件下面都是可选择的方法，每个方法都会继承component类，比如extractors有如下几种组件：</p>
<p><img src="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/extractors.png"></p>
<p>上图中<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=http://extractor.py">crf_entity_extractor.py</a>就是一个基于条件随机场提取实体的组件，RASA提供了很多种方法。当我们不满足RASA自带的这些组件时，那么就可以自定义一个组件，同样需要继承<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=http://components.py">components.py</a>中的component类。在component类中定义了一系列实例化组件的方法，主要的方法有训练 train() 、解析 process() 、持久化 persist() 、加载 load()。</p>
<p>假如我们想生成一个新的组件，可以按照以下例子书写：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lly1122334/article/details/106119731"><strong>Rasa自定义NLU组件</strong></a></p>
<p><a target="_blank" rel="noopener" href="https://blog.rasa.com/enhancing-rasa-nlu-with-custom-components/"><strong>Enhancing Rasa NLU models with Custom Components</strong></a></p>
<h5 id="2-1-2-Pipeline-Approach"><a href="#2-1-2-Pipeline-Approach" class="headerlink" title="2.1.2 Pipeline Approach"></a>2.1.2 Pipeline Approach</h5><p>【参考老师PPT课件P8-P13】补充</p>
<blockquote>
<h4 id="词向量、语言模型-Language-Models"><a href="#词向量、语言模型-Language-Models" class="headerlink" title="词向量、语言模型(Language Models)"></a>词向量、语言模型(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#language-models">Language Models</a>)</h4><ol>
<li><p>MitieNLP：<a target="_blank" rel="noopener" href="https://github.com/mit-nlp/MITIE">MIT Information Extraction</a></p>
<p>是MITIE initializer的简称，作用是初始化Mitie，每个mitie组件都依赖于此，因此应该将其放在任何使用mitie组件的每个管道的开头。如果用mitie的wordrep（作用类似word2vec）训练词向量需要很长时间，所以会事先下载好基于维基百科训练好的词向量文件，将路径赋给参数model。除此之外还有SpacyNLP和HFTransformersNLP。</p>
</li>
</ol>
<ol start="2">
<li><p>SpacyNLP</p>
</li>
<li><p>HFTransformersNLP</p>
</li>
</ol>
<h4 id="分词器-Tokenizers"><a href="#分词器-Tokenizers" class="headerlink" title="分词器(Tokenizers)"></a>分词器(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#tokenizers">Tokenizers</a>)</h4><ol>
<li><p>WhitespaceTokenizer：空格分词器</p>
</li>
<li><p>JiebaTokenizer：结巴分词器</p>
<p>用jieba进行中文的tokenize，将单词转化成id，同时需要传入自定义词典。除此之外还有MitieTokenizer、SpacyTokenizer等等。</p>
</li>
<li><p>MitieTokenizer：MITIE分词器</p>
</li>
<li><p>SpacyTokenizer：spaCy分词器</p>
</li>
<li><p>ConveRTTokenizer：ConveRT分词器</p>
</li>
<li><p>LanguageModelTokenizer</p>
</li>
</ol>
<h4 id="特征提取器-Featurizers"><a href="#特征提取器-Featurizers" class="headerlink" title="特征提取器(Featurizers)"></a>特征提取器(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#featurizers">Featurizers</a>)</h4><ol>
<li><p>MitieFeaturizer：MITIE特征提取器。使用MITIE featurizer为意图分类创建特性。</p>
</li>
<li><p>SpacyFeaturizer：spaCy特征提取器</p>
</li>
<li><p>ConveRTFeaturizer：ConveRT特征提取器</p>
</li>
<li><p>LanguageModelFeaturizer</p>
</li>
<li><p>RegexFeaturizer：正则表达式特征提取器。为实体提取和意图分类创建特性。在训练期间，regex intent featurizer 以训练数据的格式创建一系列正则表达式列表。对于每个正则，都将设置一个特征，标记是否在输入中找到该表达式，然后将其输入到intent classifier / entity extractor 中以简化分类(假设分类器在训练阶段已经学习了该特征集合，该特征集合表示一定的意图)。将Regex特征用于实体提取目前仅CRFEntityExtractor组件支持。</p>
</li>
<li><p>CountVectorsFeaturizer：词袋模型特征提取器，结合用户消息、意图和响应</p>
</li>
<li><p>LexicalSyntacticFeaturizer：词法语法特征提取器</p>
</li>
</ol>
<h4 id="意图分类器-Intent-Classifiers"><a href="#意图分类器-Intent-Classifiers" class="headerlink" title="意图分类器(Intent Classifiers)"></a>意图分类器(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#intent-classifiers">Intent Classifiers</a>)</h4><ol>
<li><p>MitieIntentClassifier: MITIE意图分类器。MitieIntentClassifier分类器里面已经自带Featurizer功能，所以不是必须配置的。简单来说，是基于稀疏线性核的一个多分类线性SVM。具体信息见：<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https://github.com/mit-nlp/MITIE">https://github.com/mit-nlp/MITIE</a>。</p>
</li>
<li><p>SklearnIntentClassifier: Sklearn意图分类器。Sklearn意图分类器训练一个线性支持向量机，该支持向量机通过网格搜索得到优化。并且将每个类别的概率排名，不管是否有类别超过预设的概率阀值。SklearnIntentClassifier使用时候需要将SVM的超参数配置上。具体配置如下：</p>
</li>
</ol>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment"># Specifies the list of regularization values to</span></span><br><span class="line"><span class="comment"># cross-validate over for C-SVM.</span></span><br><span class="line">   <span class="comment"># This is used with the ``kernel`` hyperparameter in GridSearchCV.</span></span><br><span class="line"><span class="attr">C:</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">100</span>]</span><br><span class="line">   <span class="comment"># Specifies the kernel to use with C-SVM.</span></span><br><span class="line"><span class="comment"># This is used with the ``C`` hyperparameter in GridSearchCV.</span></span><br><span class="line">   <span class="attr">kernels:</span> [<span class="string">&quot;linear&quot;</span>]</span><br><span class="line"><span class="comment"># Gamma parameter of the C-SVM.</span></span><br><span class="line">   <span class="attr">&quot;gamma&quot;:</span> [<span class="number">0.1</span>]</span><br><span class="line"><span class="comment"># We try to find a good number of cross folds to use during</span></span><br><span class="line">   <span class="comment"># intent training, this specifies the max number of folds.</span></span><br><span class="line"><span class="attr">&quot;max_cross_validation_folds&quot;:</span> <span class="number">5</span></span><br><span class="line">   <span class="comment"># Scoring function used for evaluating the hyper parameters.</span></span><br><span class="line">   <span class="comment"># This can be a name or a function.</span></span><br><span class="line">   <span class="attr">&quot;scoring_function&quot;:</span> <span class="string">&quot;f1_weighted&quot;</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li><p>EmbeddingIntentClassifier：嵌入意图分类器（即将被DIETClassifier替代）</p>
</li>
<li><p>FallbackClassifier：当意图识别的得分比较低时，使用该分类器决定是否给出nlu_fallback意图。注意，这个FallbackClassifier总是跟在其他意图分类器之后，对前一个意图分类提给出的意图及置信度进行判定。如果前一个意图分类器给出的意图预测置信度低于threshold，或者两个排名最高的意图的置信度得分接近时，<code>FallbackClassifier</code>实施回退操作。回退意图的应答，可以通过规则来实现。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rules:</span><br><span class="line">- rule: Ask the user to rephrase in case of low NLU confidence</span><br><span class="line">  steps:</span><br><span class="line">  - intent: nlu_fallback</span><br><span class="line">  - action: utter_please_rephrase</span><br></pre></td></tr></table></figure>

<p>FallbackClassifier的配置参数有：</p>
<p><strong>threshold</strong>：此参数设置预测nlu_fallback意图的阈值。如果前一个意图分类器预测的意图置信度小于threshold，则FallbackClassifier将返回一个置信度为1.0的nlu_fallback意图。</p>
<p><strong>ambiguity_threshold</strong>：如果两个排名最高的意图的置信度得分之差小于ambiguity_threshold，FallbackClassifier将返回一个置信度为1.0的nlu_fallback意图。</p>
</li>
<li><p>KeywordIntentClassifier：关键词意图分类器，适合小项目。</p>
<p>简单的关键字匹配意图分类，适用于小型项目，意图比较少的情况。当意图很多，相关性又很大的时候，关键词分类器无法区分。关键字的匹配方式是，训练数据的整句话都作为关键字，去搜索用户说的话。因此写配置数据的时候，仔细设计那个训练数据很重要，关键字不能太长，这容易匹配不上意图，也不能太短，缺少意图的区分度。</p>
</li>
<li><p><strong>DIETClassifier（Dual intent and Entity Transformer）：意图分类和实体提取的双向转换器（支持中文）</strong></p>
<p>DIET模型解决了对话理解问题中的2个问题，意图分类和实体识别。</p>
<p>DIET使用的是纯监督的方式，没有任何预训练的情况下，无须大规模预训练是关键，性能好于fine-tuning Bert, 但是训练速度是bert的6倍。输入是用户消息和可选意图的稠密或者稀疏向量。输出是实体，意图和评分。</p>
<p>DIET体系结构基于两个任务共享的Transformer。实体标签序列通过Transformer后，输出序列进入顶层条件随机场（CRF）标记层预测，输出每个Token成为BIOE的概率。完整话语和意图标签经过Transformer输出到单个语义向量空间中。利用点积损失最大化与目标标签的相似度，最小化与负样本的相似度。</p>
<p>具体DIET的算法参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/337181983">DIET: Dual Intent and Entity Transformer-RASA论文翻译</a></p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果只想将DIETClassifier用于意图分类，请将entity_recognition设置为False。</span></span><br><span class="line"><span class="comment"># 如果只想进行实体识别，请将intent_classification设置为False。</span></span><br><span class="line"><span class="comment"># 默认情况下，DIETClassifier同时执行这两项操作，即实体识别和意图分类都设置为True。</span></span><br></pre></td></tr></table></figure>

<p>可以定义多个超参数来调整模型。如果要调整模型，请首先修改以下参数：</p>
<p>epochs：此参数设置算法将看到训练数据的次数（默认值：300）。一个epoch等于所有训练实例的一个向前传播和一个向后传播。有时模型需要更多的epoch来正确学习。epoch数越少，模型的训练速度就越快。</p>
<p>hidden_layers_sizes：此参数允许您为用户消息和意图定义前馈层的数量及其输出维度（默认值：文本：[]，标签：[]）。列表中的每个条目都对应一个前馈层。例如，如果设置text:[256，128]，我们将在转换器前面添加两个前馈层。输入token的向量（来自用户消息）将被传递到这些层。第一层的输出维度为256，第二层的输出维度为128。如果使用空列表（默认行为），则不会添加前馈层。确保只使用正整数值。通常使用二次幂的数字，第二个值小于或等于前一个值。</p>
<p>embedding_dimension：该参数定义模型内部使用的嵌入层的输出维度（默认值：20）。我们在模型架构中使用了多个嵌入层。例如，在比较和计算损失之前，将完整的话语和意图的向量传递到嵌入层。</p>
<p>number_of_transformer_layers：此参数设置要使用的transformer层数（默认值：2）。transformer层的数量对应于要用于模型的transformer块。</p>
<p>transformer_size：此参数设置transformer中的单位数（默认值：256）。来自transformer的矢量将具有给定的transformer_size。</p>
<p>weight_sparsity：该参数定义模型中所有前馈层的内核权重的分数（默认值：0.8）。该值应介于0和1之间。如果将weight_sparsity设置为0，则不会将内核权重设置为0，该层将充当标准的前馈层。您不应该将weight_sparsity设置为1，因为这将导致所有内核权重为0，即模型无法学习。</p>
<p>一般来说，调整这些参数就可以获得比较好的模型。另外还有其他可以调整的参数，具体见下表。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">+---------------------------------+------------------+--------------------------------------------------------------+</span><br><span class="line">  | Parameter                       | Default Value    | Description                                                  |</span><br><span class="line">  +=================================+==================+==============================================================+</span><br><span class="line">  | hidden<span class="emphasis">_layers_</span>sizes             | text: []         | Hidden layer sizes for layers before the embedding layers    |</span><br><span class="line">   |                                 | label: []        | for user messages and labels. The number of hidden layers is |</span><br><span class="line"><span class="code">       |                                 |                  | equal to the length of the corresponding list.               |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">       | share_hidden_layers             | False            | Whether to share the hidden layer weights between user       |</span></span><br><span class="line"><span class="code">   |                                 |                  | messages and labels.                                         |</span></span><br><span class="line"><span class="code">       +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | transformer_size                | 256              | Number of units in transformer.                              |</span></span><br><span class="line"><span class="code">  +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | number_of_transformer_layers    | 2                | Number of transformer layers.                                |</span></span><br><span class="line"><span class="code">  +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | number_of_attention_heads       | 4                | Number of attention heads in transformer.                    |</span></span><br><span class="line"><span class="code">  +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | use_key_relative_attention      | False            | If &#x27;True&#x27; use key relative embeddings in attention.          |</span></span><br><span class="line"><span class="code">  +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | use_value_relative_attention    | False            | If &#x27;True&#x27; use value relative embeddings in attention.        |</span></span><br><span class="line"><span class="code">  +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | max_relative_position           | None             | Maximum position for relative embeddings.                    |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | unidirectional_encoder          | False            | Use a unidirectional or bidirectional encoder.               |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | batch_size                      | [64, 256]        | Initial and final value for batch sizes.                     |</span></span><br><span class="line"><span class="code">   |                                 |                  | Batch size will be linearly increased for each epoch.        |</span></span><br><span class="line"><span class="code">   |                                 |                  | If constant `batch_size` is required, pass an int, e.g. `8`. |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | batch_strategy                  | &quot;balanced&quot;       | Strategy used when creating batches.                         |</span></span><br><span class="line"><span class="code">   |                                 |                  | Can be either &#x27;sequence&#x27; or &#x27;balanced&#x27;.                      |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | epochs                          | 300              | Number of epochs to train.                                   |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | random_seed                     | None             | Set random seed to any &#x27;int&#x27; to get reproducible results.    |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | learning_rate                   | 0.001            | Initial learning rate for the optimizer.                     |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | embedding_dimension             | 20               | Dimension size of embedding vectors.                         |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | dense_dimension                 | text: 128        | Dense dimension for sparse features to use.                  |</span></span><br><span class="line"><span class="code">   |                                 | label: 20        |                                                              |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | concat_dimension                | text: 128        | Concat dimension for sequence and sentence features.         |</span></span><br><span class="line"><span class="code">   |                                 | label: 20        |                                                              |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | number_of_negative_examples     | 20               | The number of incorrect labels. The algorithm will minimize  |</span></span><br><span class="line"><span class="code">   |                                 |                  | their similarity to the user input during training.          |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | similarity_type                 | &quot;auto&quot;           | Type of similarity measure to use, either &#x27;auto&#x27; or &#x27;cosine&#x27; |</span></span><br><span class="line"><span class="code">   |                                 |                  | or &#x27;inner&#x27;.                                                  |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | loss_type                       | &quot;softmax&quot;        | The type of the loss function, either &#x27;softmax&#x27; or &#x27;margin&#x27;. |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | ranking_length                  | 10               | Number of top actions to normalize scores for loss type      |</span></span><br><span class="line"><span class="code">   |                                 |                  | &#x27;softmax&#x27;. Set to 0 to turn off normalization.               |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | maximum_positive_similarity     | 0.8              | Indicates how similar the algorithm should try to make       |</span></span><br><span class="line"><span class="code">   |                                 |                  | embedding vectors for correct labels.                        |</span></span><br><span class="line"><span class="code">   |                                 |                  | Should be 0.0 &lt; ... &lt; 1.0 for &#x27;cosine&#x27; similarity type.      |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | maximum_negative_similarity     | -0.4             | Maximum negative similarity for incorrect labels.            |</span></span><br><span class="line"><span class="code">   |                                 |                  | Should be -1.0 &lt; ... &lt; 1.0 for &#x27;cosine&#x27; similarity type.     |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | use_maximum_negative_similarity | True             | If &#x27;True&#x27; the algorithm only minimizes maximum similarity    |</span></span><br><span class="line"><span class="code">   |                                 |                  | over incorrect intent labels, used only if &#x27;loss_type&#x27; is    |</span></span><br><span class="line"><span class="code">   |                                 |                  | set to &#x27;margin&#x27;.                                             |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | scale_loss                      | False            | Scale loss inverse proportionally to confidence of correct   |</span></span><br><span class="line"><span class="code">   |                                 |                  | prediction.                                                  |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | regularization_constant         | 0.002            | The scale of regularization.                                 |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | negative_margin_scale           | 0.8              | The scale of how important it is to minimize the maximum     |</span></span><br><span class="line"><span class="code">   |                                 |                  | similarity between embeddings of different labels.           |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | weight_sparsity                 | 0.8              | Sparsity of the weights in dense layers.                     |</span></span><br><span class="line"><span class="code">   |                                 |                  | Value should be between 0 and 1.                             |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | drop_rate                       | 0.2              | Dropout rate for encoder. Value should be between 0 and 1.   |</span></span><br><span class="line"><span class="code">   |                                 |                  | The higher the value the higher the regularization effect.   |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | drop_rate_attention             | 0.0              | Dropout rate for attention. Value should be between 0 and 1. |</span></span><br><span class="line"><span class="code">   |                                 |                  | The higher the value the higher the regularization effect.   |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | use_sparse_input_dropout        | True             | If &#x27;True&#x27; apply dropout to sparse input tensors.             |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | use_dense_input_dropout         | True             | If &#x27;True&#x27; apply dropout to dense input tensors.              |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | evaluate_every_number_of_epochs | 20               | How often to calculate validation accuracy.                  |</span></span><br><span class="line"><span class="code">   |                                 |                  | Set to &#x27;-1&#x27; to evaluate just once at the end of training.    |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | evaluate_on_number_of_examples  | 0                | How many examples to use for hold out validation set.        |</span></span><br><span class="line"><span class="code">   |                                 |                  | Large values may hurt performance, e.g. model accuracy.      |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | intent_classification           | True             | If &#x27;True&#x27; intent classification is trained and intents are   |</span></span><br><span class="line"><span class="code">   |                                 |                  | predicted.                                                   |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | entity_recognition              | True             | If &#x27;True&#x27; entity recognition is trained and entities are     |</span></span><br><span class="line"><span class="code">   |                                 |                  | extracted.                                                   |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | use_masked_language_model       | False            | If &#x27;True&#x27; random tokens of the input message will be masked  |</span></span><br><span class="line"><span class="code">   |                                 |                  | and the model has to predict those tokens. It acts like a    |</span></span><br><span class="line"><span class="code">   |                                 |                  | regularizer and should help to learn a better contextual     |</span></span><br><span class="line"><span class="code">   |                                 |                  | representation of the input.                                 |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | tensorboard_log_directory       | None             | If you want to use tensorboard to visualize training         |</span></span><br><span class="line"><span class="code">   |                                 |                  | metrics, set this option to a valid output directory. You    |</span></span><br><span class="line"><span class="code">   |                                 |                  | can view the training metrics after training in tensorboard  |</span></span><br><span class="line"><span class="code">   |                                 |                  | via &#x27;tensorboard --logdir &lt;path-to-given-directory&gt;&#x27;.        |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | tensorboard_log_level           | &quot;epoch&quot;          | Define when training metrics for tensorboard should be       |</span></span><br><span class="line"><span class="code">   |                                 |                  | logged. Either after every epoch (&#x27;epoch&#x27;) or for every      |</span></span><br><span class="line"><span class="code">   |                                 |                  | training step (&#x27;minibatch&#x27;).                                 |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | featurizers                     | []               | List of featurizer names (alias names). Only features        |</span></span><br><span class="line"><span class="code">   |                                 |                  | coming from the listed names are used. If list is empty      |</span></span><br><span class="line"><span class="code">   |                                 |                  | all available features are used.                             |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | checkpoint_model                | False            | Save the best performing model during training. Models are   |</span></span><br><span class="line"><span class="code">   |                                 |                  | stored to the location specified by `--out`. Only the one    |</span></span><br><span class="line"><span class="code">   |                                 |                  | best model will be saved.                                    |</span></span><br><span class="line"><span class="code">   |                                 |                  | Requires `evaluate_on_number_of_examples &gt; 0` and            |</span></span><br><span class="line"><span class="code">   |                                 |                  | `evaluate_every_number_of_epochs &gt; 0`                        |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+--------------------------------------------------------------+</span></span><br><span class="line"><span class="code">   | split_entities_by_comma         | True             | Splits a list of extracted entities by comma to treat each   |</span></span><br><span class="line"><span class="code">   |                                 |                  | one of them as a single entity. Can either be `True`/`False` |</span></span><br><span class="line"><span class="code">   |                                 |                  | globally, or set per entity type, such as:                   |</span></span><br><span class="line"><span class="code">   |                                 |                  | ```                                                          |</span></span><br><span class="line"><span class="code">   |                                 |                  | ...                                                          |</span></span><br><span class="line"><span class="code">   |                                 |                  | - name: DIETClassifier                                       |</span></span><br><span class="line"><span class="code">   |                                 |                  |   split_entities_by_comma:                                   |</span></span><br><span class="line"><span class="code">   |                                 |                  |     address: True                                            |</span></span><br><span class="line"><span class="code">   |                                 |                  |     ...                                                      |</span></span><br><span class="line"><span class="code">   |                                 |                  | ...                                                          |</span></span><br><span class="line"><span class="code">   |                                 |                  | ```                                                          |</span></span><br><span class="line"><span class="code">   +---------------------------------+------------------+------------------------------------</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="实体提取器-Entity-Extractors"><a href="#实体提取器-Entity-Extractors" class="headerlink" title="实体提取器(Entity Extractors)"></a>实体提取器(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#entity-extractors">Entity Extractors</a>)</h4><ol>
<li><p>MitieEntityExtractor： MITIE实体提取器</p>
<p>Mitie是一个训练词向量和提取实体的工具库，使用分布式单词嵌入和结构支持向量机。</p>
<p>具体信息见：<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https://github.com/mit-nlp/MITIE">https://github.com/mit-nlp/MITIE</a>。</p>
<ol start="2">
<li>SpacyEntityExtractor:  spaCy实体提取器</li>
</ol>
</li>
<li><p>EntitySynonymMapper：同义词匹配实体提取器。</p>
<p>作用是将同义词映射到同一个值。比如将United States of America 和USA都映射到usa。</p>
</li>
<li><p>CRFEntityExtractor：条件随机场实体提取器</p>
</li>
<li><p>DucklingHTTPExtractor：<a target="_blank" rel="noopener" href="https://xercis.blog.csdn.net/article/details/106114511">常见实体提取器</a></p>
</li>
<li><p>DIETClassifier：意图分类和实体提取的双向转换器</p>
</li>
</ol>
<h4 id="选择器-Selectors"><a href="#选择器-Selectors" class="headerlink" title="选择器(Selectors)"></a>选择器(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#selectors">Selectors</a>)</h4><ol>
<li>ResponseSelector：响应选择器</li>
</ol>
<h4 id="合并的实体提取器和意图分类器-Combined-Intent-Classifiers-and-Entity-Extractors"><a href="#合并的实体提取器和意图分类器-Combined-Intent-Classifiers-and-Entity-Extractors" class="headerlink" title="合并的实体提取器和意图分类器(Combined Intent Classifiers and Entity Extractors)"></a>合并的实体提取器和意图分类器(<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#combined-intent-classifiers-and-entity-extractors">Combined Intent Classifiers and Entity Extractors</a>)</h4><ol>
<li>DIETClassifier：意图分类和实体提取的双向转换器</li>
</ol>
</blockquote>
<h5 id="2-1-3-Intent-Recognition"><a href="#2-1-3-Intent-Recognition" class="headerlink" title="2.1.3 Intent Recognition"></a>2.1.3 Intent Recognition</h5><p>缺少训练数据</p>
<p>OOV，在测试集中找不到对应词</p>
<p>Similar Intents 近似意图合并</p>
<p>Skewed data 避免数据倾斜</p>
<h5 id="2-1-3-Custom-Components"><a href="#2-1-3-Custom-Components" class="headerlink" title="2.1.3 Custom Components"></a>2.1.3 Custom Components</h5><p>创建自定义的类</p>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/components#custom-components">https://rasa.com/docs/rasa/components#custom-components</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.rasa.com/enhancing-rasa-nlu-with-custom-components/">https://blog.rasa.com/enhancing-rasa-nlu-with-custom-components/</a></p>
<p><img src="/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/NLUCOMPONENT.png"></p>
<h4 id="2-2-Expand-your-NLU-Data"><a href="#2-2-Expand-your-NLU-Data" class="headerlink" title="2.2 Expand your NLU Data"></a>2.2 Expand your NLU Data</h4><ol>
<li>Share your Bot to More people</li>
<li>NLU Data Augmentation 数据增强</li>
<li>Reinforce Learning 强化学习</li>
</ol>
<h3 id="三、Optimize-Policy"><a href="#三、Optimize-Policy" class="headerlink" title="三、Optimize Policy"></a>三、Optimize Policy</h3><h4 id="3-1-About-Policy"><a href="#3-1-About-Policy" class="headerlink" title="3.1 About Policy"></a>3.1 About Policy</h4><p>policy的作用：</p>
<p>决定在对话的每个步骤中应该采取的操作，可以使用的策略包括但不限于机器学习和基于规则的策略。</p>
<p>可以在项目的config.yml中指定一个或者多个策略。</p>
<p>配置中定义的每个策略都会以一定的置信度（取最高）预测下一个动作。</p>
<p>默认情况下，在每条用户消息之后，最多可以预测10个下一个动作，可以环境变量MAX_NUMBER_OF_PREDICTIONS设置为所需的最大预测数。</p>
<h4 id="3-2-About-Policy-Priority"><a href="#3-2-About-Policy-Priority" class="headerlink" title="3.2 About Policy Priority"></a>3.2 About Policy Priority</h4><p>关于策略优先级：</p>
<p>Rasa具有默认优先级，这些默认优先级被设置为确保平局时的预期结果，数字越高优先级越高，如下：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">6</span> <span class="bullet">-</span> <span class="string">RulePolicy</span></span><br><span class="line"><span class="number">3</span> <span class="bullet">-</span> <span class="string">MemoizationPolicy</span> <span class="string">or</span> <span class="string">AugmentedMemoizationPolicy</span></span><br><span class="line"><span class="number">1</span> <span class="bullet">-</span> <span class="string">TEDPolicy</span></span><br></pre></td></tr></table></figure>
<p>一般地，在配置中的每个优先级不建议使用多个策略。</p>
<p>如果有2个策略具有相同的优先级，并且它们以相同的置信度进行预测，则将随机选择结果操作。</p>
<h4 id="3-3-Policies"><a href="#3-3-Policies" class="headerlink" title="3.3 Policies"></a>3.3 Policies</h4><p>有哪些对话<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/core/policies/">策略</a>：</p>
<p>一、机器学习策略：</p>
<p><strong>1、TED(Transformer Embedding Dialogue) Policy</strong></p>
<p>用于下一动作预测和实体识别的多任务架构策略（具体实施细节待进一步理解）。</p>
<p><strong>2、Memoization Policy</strong></p>
<p>记忆策略只记录训练数据中的对话</p>
<p>若训练数据存在这样的对话，则以置信度1.0预测下一个动作，否则以0.0预测</p>
<p>一般不单独使用</p>
<p><strong>3、Augmented Memoization Policy</strong></p>
<p>AugmentedMemoizationPolicy可以记住训练story中的示例，直到max_history。</p>
<p>具有遗忘机制，可以遗忘对话历史记录中的某些步骤，并尝试在历史减少的story中找到匹配项</p>
<p>二、Rule-based Policies</p>
<p><strong>1、Rule Policy</strong></p>
<p>一种处理遵循固定行为（例如，业务逻辑）的对话部分的策略。它根据您的训练数据中的任何规则进行预测。</p>
<p>三、Custom Policies</p>
<p>编写自定义测策略：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In the example below, the last two lines show how to use a custom policy class and pass arguments to it.</span></span><br><span class="line"><span class="attr">policies:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;TEDPolicy&quot;</span></span><br><span class="line">    <span class="attr">max_history:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">epochs:</span> <span class="number">200</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;RulePolicy&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;path.to.your.policy.class&quot;</span></span><br><span class="line">    <span class="attr">arg1:</span> <span class="string">&quot;...&quot;</span></span><br></pre></td></tr></table></figure>


<p><del>*四、其他已弃用的策略</del>*</p>
<p><em><del>1、 Mapping Policy</del></em></p>
<p><em><del>映射策略将意图映射为操作</del></em></p>
<p><em><del>无视之前对话，一旦触发意图就操作</del></em></p>
<p><em><del>映射是传递intent属性给<code>triggers</code>实现的，修改<code>domain.yml</code></del></em></p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">intents:</span><br><span class="line"><span class="bullet">   -</span> ask<span class="emphasis">_is_</span>bot:</span><br><span class="line"><span class="code">    triggers: action_is_bot</span></span><br><span class="line"><span class="code"> 123</span></span><br></pre></td></tr></table></figure>
<p><em><del>一般不单独使用。</del></em></p>
<p><em><del>2、 Form Policy</del></em></p>
<p><em><del>表单策略，收集指定信息，如性别年龄地址</del></em></p>
<p> <em><del>需要实现FormAction，在<code>domain.yml</code>中指定，在<code>stories.md</code>中使用</del></em></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">forms:</span><br><span class="line"> - facility_form</span><br></pre></td></tr></table></figure>
<p><em><del>3、Fallback Policy</del></em></p>
<p><em><del>回退策略，聊天机器人不可避免需要的回退情况，例如用户问了让机器人理解不了的东西时需要回退</del></em></p>
<p><em><del>需要提供阈值</del></em></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">policies:</span><br><span class="line"><span class="bullet"> -</span> name: FallbackPolicy</span><br><span class="line"><span class="code">    nlu_threshold: 0.3</span></span><br><span class="line"><span class="code">   ambiguity_threshold: 0.1</span></span><br><span class="line"><span class="code">    core_threshold: 0.3</span></span><br><span class="line"><span class="code">    fallback_action_name: &#x27;action_default_fallback&#x27;</span></span><br><span class="line"><span class="code">123456</span></span><br></pre></td></tr></table></figure>
<p><em><del>4、Two-Stage Fallback Policy</del></em></p>
<p> <del>不直接回退而是让用户选，尝试消除用户输入的歧义，从而在多个阶段处理NLU可信度较低的问题。</del></p>
<h4 id="3-4-Configuring-Policies"><a href="#3-4-Configuring-Policies" class="headerlink" title="3.4 Configuring Policies"></a>3.4 Configuring Policies</h4><p>配置对话策略</p>
<p>Max History：是RASA中一个重要的超参数，用于控制模型查看多少对话历史记录，以决定下一步应采取的行动。</p>
<p>在config.yml文件中，Max History的默认值为“无”，这表示自会话重新启动以来的完整对话历史记录已记入该帐户。</p>
<blockquote>
<p>RulePolicy没有max history参数，它始终考虑所提供规则的完整长度。</p>
</blockquote>
<p>例子：</p>
<p>假设有一个out_of_scope意图，该意图描述了主题外的用户消息。如果机器人连续多次看到此意图，则可能要告诉用户可以提供哪些帮助。</p>
<p>因此您的story可能如下所示：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">stories:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">story:</span> <span class="string">utter</span> <span class="string">help</span> <span class="string">after</span> <span class="number">2</span> <span class="string">fallbacks</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">out_of_scope</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_default</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">out_of_scope</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_default</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">out_of_scope</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_help_message</span></span><br></pre></td></tr></table></figure>
<p>为了让模型学习此模式，max_history必须至少为4<strong>（不应是3吗？）</strong>。</p>
<p>如果增加max_history，则模型将变大，并且训练将花费更长的时间。</p>
<p>如果有一些将来可能会影响对话的信息，则应将其存储为一个槽位，槽信息始终可用于每个功能块。</p>
<h4 id="3-5-Data-Augmentation"><a href="#3-5-Data-Augmentation" class="headerlink" title="3.5 Data Augmentation"></a>3.5 Data Augmentation</h4><p>训练模型时，Rasa Open Source将通过随机组合story文件中的story来创建更长的story，例子如下：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">stories:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">story:</span> <span class="string">thank</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">thankyou</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_youarewelcome</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">story:</span> <span class="string">say</span> <span class="string">goodbye</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">goodbye</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_goodbye</span></span><br></pre></td></tr></table></figure>
<p>实际上想让policy在无关的对话历史记录时忽略它，并且无论以前发生了什么，都要以相同的动作做出响应。</p>
<p>可以使用–augmentation标志更改此行为，该标志使您可以设置expandation_factor。 growth_factor确定在训练期间对多少个增强story进行了二次采样。扩增后的story在训练之前进行了二次抽样，因为它们的数量很快就会变得非常大，并且您希望对其进行限制。样本story的数量是增强因子x10。默认情况下，扩充设置为20，最多可生成200个扩充story。</p>
<p>–augmentation 0禁用所有扩充行为。基于备忘的策略不受扩充的影响（与扩充因素无关），并且将自动忽略所有扩充的story。</p>
<h4 id="3-6-Featurizers"><a href="#3-6-Featurizers" class="headerlink" title="3.6 Featurizers"></a>3.6 Featurizers</h4><h5 id="3-6-1-State-Featurizers"><a href="#3-6-1-State-Featurizers" class="headerlink" title="3.6.1 State Featurizers"></a>3.6.1 State Featurizers</h5><h5 id="3-6-2-Tracker-Featurizers"><a href="#3-6-2-Tracker-Featurizers" class="headerlink" title="3.6.2 Tracker Featurizers"></a>3.6.2 Tracker Featurizers</h5><h3 id="四、Action-Server"><a href="#四、Action-Server" class="headerlink" title="四、Action Server"></a>四、Action Server</h3><h4 id="4-1-ACTION"><a href="#4-1-ACTION" class="headerlink" title="4.1 ACTION"></a>4.1 ACTION</h4><p>Action类是任何自定义操作的基类。要定义自定义的action，请创建Action类的子类并覆盖两个必需的方法，即name和run。</p>
<p>样例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># See this guide on how to implement these action:</span></span><br><span class="line"><span class="comment"># https://rasa.com/docs/rasa/custom-actions</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># This is a simple example for a custom action which utters &quot;Hello World!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># from typing import Any, Text, Dict, List</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># from rasa_sdk import Action, Tracker</span></span><br><span class="line"><span class="comment"># from rasa_sdk.executor import CollectingDispatcher</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># class ActionHelloWorld(Action):</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def name(self) -&gt; Text:</span></span><br><span class="line"><span class="comment">#         return &quot;action_hello_world&quot;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def run(self, dispatcher: CollectingDispatcher,</span></span><br><span class="line"><span class="comment">#             tracker: Tracker,</span></span><br><span class="line"><span class="comment">#             domain: Dict[Text, Any]) -&gt; List[Dict[Text, Any]]:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         dispatcher.utter_message(text=&quot;Hello World!&quot;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         return []</span></span><br></pre></td></tr></table></figure>
<p>上述<code>def name(self) -&gt; Text:</code>是<strong>函数参数注解，用于提示该函数的输入参数和返回值的类型</strong>，方便阅读。</p>
<p>python解释器不会对这些注解添加任何的语义。它们不会被类型检查，运行时跟没有加注解之前的效果也没有任何差距</p>
<p>当action server收到运行动作的请求时，它将根据其name方法的返回值调用的action。</p>
<h4 id="4-2-Events"><a href="#4-2-Events" class="headerlink" title="4.2 Events"></a>4.2 Events</h4><p>Rasa中的会话表示为一系列事件。自定义动作可以通过在对动作服务器请求的响应中返回事件来影响对话的过程。</p>
<p>并非所有事件通常都是由自定义操作返回的，因为Rasa会自动跟踪它们（例如，用户消息）。如果其他事件是由自定义操作返回的，则只能对其进行跟踪。</p>
<h4 id="4-3-Knowledge-Base-Actions"><a href="#4-3-Knowledge-Base-Actions" class="headerlink" title="4.3 Knowledge Base Actions"></a>4.3 Knowledge Base Actions</h4><p><code>ActionQueryKnowledgeBase</code></p>
<h3 id="五、More-Concepts"><a href="#五、More-Concepts" class="headerlink" title="五、More Concepts"></a>五、More Concepts</h3><h4 id="5-1-Tracker-Store"><a href="#5-1-Tracker-Store" class="headerlink" title="5.1 Tracker Store"></a>5.1 Tracker Store</h4><p>对话存储在跟踪存储中， Rasa Open Source提供了针对不同存储类型的开箱即用的实现，或者可以创建自己的自定义存储类型。</p>
<ul>
<li><p>InMemoryTrackerStore (default）：默认跟踪器存储。如果未配置其他跟踪器存储，则使用它。它将对话历史记录存储在内存中。</p>
</li>
<li><p>SQLTrackerStore：用SQLTrackerStore将助手的对话历史记录存储在SQL数据库中- </p>
</li>
<li><p>RedisTrackerStore：使用RedisTrackerStore将助手的对话历史记录存储在Redis中。 Redis是一种快速的内存中键值存储，可以选择持久存储数据。</p>
</li>
<li><p>MongoTrackerStore：使用MongoTrackerStore将助手的对话历史记录存储在MongoDB中。 MongoDB是一个免费且开源的跨平台面向文档的NoSQL数据库</p>
</li>
<li><p>DynamoTrackerStore：使用DynamoTrackerStore将助手的对话历史记录存储在DynamoDB中。 DynamoDB是Amazon Web Services（AWS）提供的托管NoSQL数据库。</p>
</li>
<li><p>Custom Tracker Store：如果需要开箱即用的跟踪器存储，则可以实施自己的跟踪器存储。这是通过扩展基类TrackerStore来完成的。</p>
</li>
</ul>
<h4 id="5-2-Event-Broker-事件代理"><a href="#5-2-Event-Broker-事件代理" class="headerlink" title="5.2 Event Broker 事件代理"></a>5.2 Event Broker 事件代理</h4><p>使用事件代理，可以将正在运行的助手连接到其他服务，这些服务处理来自对话的数据。例如，您可以将实时助手连接到Rasa X，以查看和注释对话或将消息转发到外部分析服务。事件代理将消息发布到消息流服务（也称为消息代理），以将Rasa事件从Rasa服务器转发到其他服务。</p>
<h4 id="5-3-Model-Storage"><a href="#5-3-Model-Storage" class="headerlink" title="5.3 Model Storage"></a>5.3 Model Storage</h4><p>模型可以存储在不同的位置，有三种不同的方式加载训练好的模型：</p>
<p>1、从本地磁盘加载模型（请参阅从磁盘加载模型） </p>
<p>2、从自己的HTTP服务器获取模型（请参阅从服务器加载模型）</p>
<p>3、从像S3这样的云存储中获取模型（请参阅从云中加载模型）</p>
<h4 id="5-4-Lock-Store"><a href="#5-4-Lock-Store" class="headerlink" title="5.4 Lock Store"></a>5.4 Lock Store</h4><p>Rasa使用票证锁定机制来确保以正确的顺序处理给定对话ID的传入消息，并在主动处理消息时锁定对话。这意味着多个Rasa服务器可以作为复制服务并行运行，并且在发送给定对话ID的消息时，客户端不一定需要寻址同一节点。</p>
<ul>
<li>InMemoryLockStore是默认的锁存储。它在单个进程中维护会话锁定。</li>
<li>RedisLockStore使用Redis作为持久层来维护会话锁定。建议使用此锁存储来运行一组复制的Rasa服务器。</li>
</ul>
<h4 id="5-4-Importer"><a href="#5-4-Importer" class="headerlink" title="5.4 Importer"></a>5.4 Importer</h4><p>Rasa Open Source具有内置的逻辑来收集和加载以Rasa格式编写的训练数据，但是您也可以使用自定义训练数据导入器自定义如何导入训练数据。</p>
<ul>
<li><p>RasaFileImporter</p>
<p>默认情况下，Rasa使用导入程序RasaFileImporter。如果要单独使用它，则无需在配置文件中指定任何内容。如果要与其他导入程序一起使用，请将其添加到配置文件中</p>
</li>
<li><p>MultiProjectImporter</p>
<p>使用此导入器，可以通过组合多个可重复使用的Rasa项目来训练模型。例如，可能用一个项目处理闲聊，而用另一个项目问候您的用户</p>
</li>
<li><p>Writing a Custom Importer</p>
<p>如果要编写自定义导入器，则需要实现TrainingDataImporter的接口。</p>
</li>
</ul>
<h4 id="5-4-Dispatcher"><a href="#5-4-Dispatcher" class="headerlink" title="5.4 Dispatcher"></a>5.4 Dispatcher</h4><p>调度程序是CollectingDispatcher类的实例，用于生成响应以发送回用户。</p>
<p>CollectingDispatcher具有一种方法utter_message和一种属性（消息）。</p>
<p>在action的run方法中使用它来添加对返回到Rasa服务器的有效负载的响应。</p>
<p>Rasa服务器将依次为每个响应将BotUttered事件添加到跟踪器。因此，使用分派器添加的响应不应作为事件显式返回。</p>
<h3 id="六、Deployment"><a href="#六、Deployment" class="headerlink" title="六、Deployment"></a>六、Deployment</h3><h4 id="6-1-推荐的部署方法"><a href="#6-1-推荐的部署方法" class="headerlink" title="6.1 推荐的部署方法"></a>6.1 推荐的部署方法</h4><ul>
<li>快速安装一个服务：</li>
</ul>
<p>服务器快速安装脚本是部署Rasa X和您的助手的最简单方法。它会使用合理的默认值在您的机器上安装Kubernetes集群，使您可以通过一条命令启动并运行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s get-rasa-x.rasa.com | sudo bash</span><br></pre></td></tr></table></figure>
<ul>
<li>Helm Chart</li>
</ul>
<p>对于将吸引大量用户流量的助手，通过我们的Helm图表设置Kubernetes或Openshift部署是最佳选择。Helm提供了可伸缩的体系结构，该体系结构也易于部署。</p>
<h4 id="6-2-其他可选方法"><a href="#6-2-其他可选方法" class="headerlink" title="6.2 其他可选方法"></a>6.2 其他可选方法</h4><ul>
<li>Docker Compose</li>
</ul>
<h4 id="6-3-部署Action-Server"><a href="#6-3-部署Action-Server" class="headerlink" title="6.3 部署Action Server"></a>6.3 部署Action Server</h4><ul>
<li><a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/how-to-deploy#building-an-action-server-image">Building an Action Server Image</a></li>
<li><a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/how-to-deploy#using-your-custom-action-server-image">Using your Custom Action Server Image</a></li>
</ul>
<h3 id="其他补充："><a href="#其他补充：" class="headerlink" title="其他补充："></a>其他补充：</h3><blockquote>
<h4 id="2-0-1、Training-Data-Format"><a href="#2-0-1、Training-Data-Format" class="headerlink" title="2.0.1、Training Data Format"></a>2.0.1、Training Data Format</h4><h5 id="2-1-1-training-data"><a href="#2-1-1-training-data" class="headerlink" title="2.1.1 [training data]"></a>2.1.1 [training data]</h5><p>Including NLU data, stories and rules.</p>
<p>You can split the training data over any number of YAML files, and each file can contain any combination of NLU data, stories, and rules.</p>
<p>你可以将训练数据划分为任意数量的YAML文件，并且每个文件可以包含NLU数据，stories和Rules的任意组合。训练数据的类型由数据最外层的key决定。</p>
<p>a short example which keeps all training data in a single file:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&gt;version:</span> <span class="string">&quot;2.0&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">nlu:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">greet</span></span><br><span class="line">  <span class="attr">examples:</span> <span class="string">|</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Hey</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Hi</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hey</span> <span class="string">there</span> [<span class="string">Sara</span>]<span class="string">(name)</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">faq/language</span></span><br><span class="line">  <span class="attr">examples:</span> <span class="string">|</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">What</span> <span class="string">language</span> <span class="string">do</span> <span class="string">you</span> <span class="string">speak?</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Do</span> <span class="string">you</span> <span class="string">only</span> <span class="string">handle</span> <span class="string">english?</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stories:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">story:</span> <span class="string">greet</span> <span class="string">and</span> <span class="string">faq</span></span><br><span class="line">  <span class="attr">steps:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">greet</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_greet</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">faq</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_faq</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">rule:</span> <span class="string">Greet</span> <span class="string">user</span></span><br><span class="line">  <span class="attr">steps:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">intent:</span> <span class="string">greet</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">utter_greet</span></span><br></pre></td></tr></table></figure>



<h5 id="2-1-2-Domain"><a href="#2-1-2-Domain" class="headerlink" title="2.1.2 [Domain]"></a>2.1.2 [Domain]</h5><p>结论：**<a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/domain">Domain文件</a>**定义了意图，实体，位置，响应，形式和动作。</p>
<p>The domain defines the universe(宇宙，全局，世界) in which your assistant operates. It specifies(指定，列举) the intents, entities, slots, responses, forms, and actions your bot should know about. It also defines a configuration for conversation sessions.</p>
<p>The <a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/glossary#domain">domain</a> uses the same YAML format as the training data and can also be split across multiple files or combined in one file. The domain includes the definitions for <a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/responses">responses</a> and <a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/forms">forms</a>. </p>
<p>a full example of a domain, taken from the <a target="_blank" rel="noopener" href="https://github.com/RasaHQ/rasa/tree/master/examples/concertbot">concertbot</a> example:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&gt;version:</span> <span class="string">&quot;2.0&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&gt;intents:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">affirm</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">deny</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">greet</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">thankyou</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">goodbye</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">search_concerts</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">search_venues</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">compare_reviews</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">bot_challenge</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nlu_fallback</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">how_to_get_started</span></span><br><span class="line"></span><br><span class="line"><span class="attr">entities:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">name</span></span><br><span class="line"></span><br><span class="line"><span class="attr">slots:</span></span><br><span class="line">  <span class="attr">concerts:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">list</span></span><br><span class="line">    <span class="attr">influence_conversation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">venues:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">list</span></span><br><span class="line">    <span class="attr">influence_conversation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">likes_music:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">bool</span></span><br><span class="line">    <span class="attr">influence_conversation:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">responses:</span></span><br><span class="line">  <span class="attr">utter_greet:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;Hey there!&quot;</span></span><br><span class="line">  <span class="attr">utter_goodbye:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;Goodbye :(&quot;</span></span><br><span class="line">  <span class="attr">utter_default:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;Sorry, I didn&#x27;t get that, can you rephrase?&quot;</span></span><br><span class="line">  <span class="attr">utter_youarewelcome:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;You&#x27;re very welcome.&quot;</span></span><br><span class="line">  <span class="attr">utter_iamabot:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;I am a bot, powered by Rasa.&quot;</span></span><br><span class="line">  <span class="attr">utter_get_started:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;I can help you find concerts and venues. Do you like music?&quot;</span></span><br><span class="line">  <span class="attr">utter_awesome:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">&quot;Awesome! You can ask me things like \&quot;Find me some concerts\&quot; or \&quot;What&#x27;s a good venue\&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">actions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">action_search_concerts</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">action_search_venues</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">action_show_concert_reviews</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">action_show_venue_reviews</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">action_set_music_preference</span></span><br><span class="line"></span><br><span class="line"><span class="attr">session_config:</span></span><br><span class="line">  <span class="attr">session_expiration_time:</span> <span class="number">60</span>  <span class="comment"># value in minutes</span></span><br><span class="line">  <span class="attr">carry_over_slots_to_new_session:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

</blockquote>
<blockquote>
<p>Tokenizer：分词器；编译器 </p>
<p>Token：<br>【计算机科学技术】单点登陆，记号，权杖，</p>
<p>【电子、通信与自动控制技术】令牌，权标 ，许可证 </p>
<p>【经济学】代价券，礼券 </p>
<p>【化学】表征 </p>
<p>【能源科学技术】表征 </p>
<p>【历史学】私铸货币 </p>
<p>Tokenization:</p>
<p>标记化</p>
</blockquote>
<blockquote>
<p>WhitespaceTokenizer：</p>
<p>Tokenizer using whitespace as a separator</p>
<p>NER：Name Entity Recognition</p>
</blockquote>
<p><strong>Reference：</strong></p>
<p>1、<a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103954937">Rasa教程系列-NLU-1-训练集格式</a></p>
<p>2、<a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103960020/">Rasa教程系列-NLU-2- 选择pipeline</a></p>
<p>3、<a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103962384">Rasa教程系列-NLU-3-实体抽取</a></p>
<p>4、<a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103975263">Rasa教程系列-NLU-4-组件</a></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103912756">Rasa教程系列-0-Rasa安装和项目创建</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103915763">Rasa教程系列-1-命令行交互</a></p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103977395">Rasa教程系列-Core-1-Stories</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103989971">Rasa教程系列-Core-2-Domains</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103991346">Rasa教程系列-Core-3-Responses</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/103993800">Rasa教程系列-Core-4-Actions</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/104002385">Rasa教程系列-Core-5-Policies</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/104018940">Rasa教程系列-Core-6-Slots</a></p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/88112269">rasa文章导引</a></p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://jiangdg.blog.csdn.net/article/details/104328946">Rasa中文聊天机器人开发指南(1)：入门篇</a></li>
<li><a target="_blank" rel="noopener" href="https://jiangdg.blog.csdn.net/article/details/104530994">Rasa中文聊天机器人开发指南(2)：NLU篇</a></li>
<li><a target="_blank" rel="noopener" href="https://jiangdg.blog.csdn.net/article/details/105434136">Rasa中文聊天机器人开发指南(3)：Core篇</a></li>
</ul>

    </div>

    
    
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;"> ------ 本文结束------</div>
    
</div>
        <div class="reward-container">
  <div>Donate comment here.</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="进军要努力呀 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="进军要努力呀 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>进军要努力呀
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://marchboy.github.io/2021/01/11/Week3-RASA%E6%BA%90%E7%A0%81%E5%92%8C%E5%AE%9A%E5%88%B6%E5%8C%96%E4%BD%A0%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/" title="week3-RASA源码和定制化你的对话机器人">https://marchboy.github.io/2021/01/11/Week3-RASA源码和定制化你的对话机器人/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
              <a href="/tags/%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D/" rel="tag"><i class="fa fa-tag"></i> 任务型对话</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/01/04/Week2-%E4%BD%BF%E7%94%A8RASA%E5%88%B6%E4%BD%9C%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%BA%E5%99%A8%E4%BA%BA/" rel="prev" title="week2-使用RASA制作你的第一个对话机器人">
      <i class="fa fa-chevron-left"></i> week2-使用RASA制作你的第一个对话机器人
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/02/02/Week4-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%90%86%E8%A7%A3NLU/" rel="next" title="week4-自然语言理解NLU">
      week4-自然语言理解NLU <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-gitalk">gitalk</a></li>
            <li class="tab"><a href="#comment-valine">valine</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane gitalk" id="comment-gitalk">
              <div class="comments" id="gitalk-container"></div>
            </div>
            <div class="tab-pane valine" id="comment-valine">
              <div class="comments" id="valine-comments"></div>
            </div>
        </div>
      </div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81Setting-up-RASA-Source-Code"><span class="nav-number">1.</span> <span class="nav-text">一、Setting up RASA Source Code</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81Optimize-NLU"><span class="nav-number">2.</span> <span class="nav-text">二、Optimize NLU</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-0-%E5%A6%82%E4%BD%95%E5%A2%9E%E5%BC%BARASA-NLU-Lifestyle"><span class="nav-number">2.1.</span> <span class="nav-text">2.0 如何增强RASA NLU - Lifestyle</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1%E3%80%81Improve-NLU"><span class="nav-number">2.2.</span> <span class="nav-text">2.1、Improve NLU</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-0%E3%80%81RASA-NLU-%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.1.0、RASA NLU 模块的作用</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1%E3%80%81Components%E7%BB%84%E4%BB%B6"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.1.1、Components组件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-Pipeline-Approach"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.1.2 Pipeline Approach</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%8D%E5%90%91%E9%87%8F%E3%80%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-Language-Models"><span class="nav-number">2.3.</span> <span class="nav-text">词向量、语言模型(Language Models)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E8%AF%8D%E5%99%A8-Tokenizers"><span class="nav-number">2.4.</span> <span class="nav-text">分词器(Tokenizers)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8-Featurizers"><span class="nav-number">2.5.</span> <span class="nav-text">特征提取器(Featurizers)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%84%8F%E5%9B%BE%E5%88%86%E7%B1%BB%E5%99%A8-Intent-Classifiers"><span class="nav-number">2.6.</span> <span class="nav-text">意图分类器(Intent Classifiers)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E4%BD%93%E6%8F%90%E5%8F%96%E5%99%A8-Entity-Extractors"><span class="nav-number">2.7.</span> <span class="nav-text">实体提取器(Entity Extractors)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%89%E6%8B%A9%E5%99%A8-Selectors"><span class="nav-number">2.8.</span> <span class="nav-text">选择器(Selectors)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E7%9A%84%E5%AE%9E%E4%BD%93%E6%8F%90%E5%8F%96%E5%99%A8%E5%92%8C%E6%84%8F%E5%9B%BE%E5%88%86%E7%B1%BB%E5%99%A8-Combined-Intent-Classifiers-and-Entity-Extractors"><span class="nav-number">2.9.</span> <span class="nav-text">合并的实体提取器和意图分类器(Combined Intent Classifiers and Entity Extractors)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-3-Intent-Recognition"><span class="nav-number">2.9.1.</span> <span class="nav-text">2.1.3 Intent Recognition</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-3-Custom-Components"><span class="nav-number">2.9.2.</span> <span class="nav-text">2.1.3 Custom Components</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Expand-your-NLU-Data"><span class="nav-number">2.10.</span> <span class="nav-text">2.2 Expand your NLU Data</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81Optimize-Policy"><span class="nav-number">3.</span> <span class="nav-text">三、Optimize Policy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-About-Policy"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 About Policy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-About-Policy-Priority"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 About Policy Priority</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-Policies"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 Policies</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-Configuring-Policies"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 Configuring Policies</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-5-Data-Augmentation"><span class="nav-number">3.5.</span> <span class="nav-text">3.5 Data Augmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-6-Featurizers"><span class="nav-number">3.6.</span> <span class="nav-text">3.6 Featurizers</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-6-1-State-Featurizers"><span class="nav-number">3.6.1.</span> <span class="nav-text">3.6.1 State Featurizers</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-6-2-Tracker-Featurizers"><span class="nav-number">3.6.2.</span> <span class="nav-text">3.6.2 Tracker Featurizers</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81Action-Server"><span class="nav-number">4.</span> <span class="nav-text">四、Action Server</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-ACTION"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 ACTION</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-Events"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 Events</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-Knowledge-Base-Actions"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 Knowledge Base Actions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94%E3%80%81More-Concepts"><span class="nav-number">5.</span> <span class="nav-text">五、More Concepts</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-Tracker-Store"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 Tracker Store</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-Event-Broker-%E4%BA%8B%E4%BB%B6%E4%BB%A3%E7%90%86"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 Event Broker 事件代理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-3-Model-Storage"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 Model Storage</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-4-Lock-Store"><span class="nav-number">5.4.</span> <span class="nav-text">5.4 Lock Store</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-4-Importer"><span class="nav-number">5.5.</span> <span class="nav-text">5.4 Importer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-4-Dispatcher"><span class="nav-number">5.6.</span> <span class="nav-text">5.4 Dispatcher</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AD%E3%80%81Deployment"><span class="nav-number">6.</span> <span class="nav-text">六、Deployment</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-%E6%8E%A8%E8%8D%90%E7%9A%84%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 推荐的部署方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-%E5%85%B6%E4%BB%96%E5%8F%AF%E9%80%89%E6%96%B9%E6%B3%95"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 其他可选方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-%E9%83%A8%E7%BD%B2Action-Server"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 部署Action Server</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E8%A1%A5%E5%85%85%EF%BC%9A"><span class="nav-number">7.</span> <span class="nav-text">其他补充：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-0-1%E3%80%81Training-Data-Format"><span class="nav-number">7.1.</span> <span class="nav-text">2.0.1、Training Data Format</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-training-data"><span class="nav-number">7.1.1.</span> <span class="nav-text">2.1.1 [training data]</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-Domain"><span class="nav-number">7.1.2.</span> <span class="nav-text">2.1.2 [Domain]</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="进军要努力呀"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">进军要努力呀</p>
  <div class="site-description" itemprop="description">可怕的是自己内心的堕落</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/marchboy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;marchboy" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jjgdut@gmail.com" title="E-Mail → mailto:jjgdut@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://plus.google.com/yourname" title="Google → https:&#x2F;&#x2F;plus.google.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>Google</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://youtube.com/yourname" title="YouTube → https:&#x2F;&#x2F;youtube.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.cnblogs.com/pinard" title="https:&#x2F;&#x2F;www.cnblogs.com&#x2F;pinard" rel="noopener" target="_blank">刘建平Pinard</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://vel.life/" title="https:&#x2F;&#x2F;vel.life&#x2F;" rel="noopener" target="_blank">思维之海</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://wulc.me/" title="https:&#x2F;&#x2F;wulc.me&#x2F;" rel="noopener" target="_blank">吴良超的学习笔记</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/IT_job" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;IT_job" rel="noopener" target="_blank">IT_job的博客</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.zdaiot.com/categories/" title="https:&#x2F;&#x2F;www.zdaiot.com&#x2F;categories&#x2F;" rel="noopener" target="_blank">zdaiot</a>
        </li>
    </ul>
  </div>


      </div>
	 <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1858139145&auto=0&height=66"></iframe>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">进军要努力呀</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">188k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:51</span>
</div><!-- ����ҳ�ײ�������վ����ʱ�� -->
<span id="timeDate">��������...</span><span id="times">����ʱ����...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("09/01/2020 00:00:00");//�˴��޸���Ľ�վʱ�������վ����ʱ��
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "Run for "+dnum+" Days ";
        document.getElementById("times").innerHTML = hnum + " Hours " + mnum + " m " + snum + " s";
    }
setInterval("createtime()",250);
</script>



    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '9de70fca612487225ccc',
      clientSecret: 'c5242111211342b5c4846f7f261816d1940d3996',
      repo        : 'marchboy.github.io',
      owner       : 'marchboy',
      admin       : ['marchboy'],
      id          : '3a8794ca87e5b49469410718ce1dcd69',
        language: '',
      distractionFreeMode: false
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qAoqMWohGTiECb1RgaNqvgNB-MdYXbMMI',
      appKey     : 'ISI8QFSo7GcRyExPHSjMkz7R',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
